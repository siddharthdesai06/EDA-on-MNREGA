{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df907611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dddf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mnrega_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4921a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_column = 'Job cards issued'\n",
    "y_column = 'Total person days'\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df[x_column], df[y_column], alpha=0.5)\n",
    "plt.xlabel('Job Cards Issued')\n",
    "plt.ylabel('Total Person-Days Worked')\n",
    "plt.title('Scatter Plot: Job Cards Issued vs. Total Person-Days Worked')\n",
    "plt.grid(True)\n",
    "\n",
    "states = df['State'].unique()\n",
    "for state in states:\n",
    "    state_data = df[df['State'] == state]\n",
    "    plt.scatter(state_data[x_column], state_data[y_column], alpha=0.5, label=state)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a09d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "\n",
    "# Select the features you want to include in the scatter plot\n",
    "features_to_plot = [\n",
    "       'Households that applied for a job card', 'Job cards issued',\n",
    "       'Job cards issued for scheduled caste',\n",
    "       'Job cards issued for scheduled tribes',\n",
    "       'Job cards issued for non scheduled tribes or scheduled caste',\n",
    "       'Households that demanded work', 'Persons who demanded work',\n",
    "       'Households that were allotted work', 'Persons that were allotted work',\n",
    "       'Muster rolls filled',\n",
    "       'Households that worked under mahatma gandhi national rural employment guarantee act (mgnrega)',\n",
    "       'Persons that worked under mahatma gandhi national rural employment guarantee act (mgnrega)',\n",
    "       'Households that reached a 100 day limit', 'Persons with disability',\n",
    "       'Non scheduled tribes or scheduled caste houeholds that worked',\n",
    "       'Total person days worked by non scheduled tribes or scheduled caste persons.',\n",
    "       'Scheduled caste houeholds that worked',\n",
    "       'Total person days worked scheduled caste persons',\n",
    "       'Scheduled tribe houeholds that worked',\n",
    "       'Total person days worked scheduled tribe persons',\n",
    "       'Households that worked on land reform or indira awas yojana',\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, feature in enumerate(features_to_plot):\n",
    "    plt.scatter(data.index, data[feature], label=feature, alpha=0.7)\n",
    "\n",
    "plt.title('Scatter Plot for many Features')\n",
    "plt.xlabel('Data Points')\n",
    "plt.ylabel('Feature Values')\n",
    "# plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1697bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "\n",
    "features_to_plot = [\n",
    "       'Households that applied for a job card', 'Job cards issued',\n",
    "       'Job cards issued for scheduled caste',\n",
    "       'Job cards issued for scheduled tribes',\n",
    "       'Job cards issued for non scheduled tribes or scheduled caste',\n",
    "       'Households that demanded work', 'Persons who demanded work',\n",
    "       'Households that were allotted work', 'Persons that were allotted work',\n",
    "       'Muster rolls filled',\n",
    "       'Households that worked under mahatma gandhi national rural employment guarantee act (mgnrega)',\n",
    "       'Persons that worked under mahatma gandhi national rural employment guarantee act (mgnrega)',\n",
    "       'Households that reached a 100 day limit', 'Persons with disability',\n",
    "       'Non scheduled tribes or scheduled caste houeholds that worked',\n",
    "       'Total person days worked by non scheduled tribes or scheduled caste persons.',\n",
    "       'Scheduled caste houeholds that worked',\n",
    "       'Total person days worked scheduled caste persons',\n",
    "       'Scheduled tribe houeholds that worked',\n",
    "       'Total person days worked scheduled tribe persons',\n",
    "       'Households that worked on land reform or indira awas yojana',\n",
    "        'Scheduled caste households that reached a 100 day limit',\n",
    "       'Scheduled tribe households that reached a 100 day limit',\n",
    "       'Labour expenditure that has been disbursed',\n",
    "       'Material expenditure that has been disbursed',\n",
    "       'Labour expenditure both disbursed and pending',\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "# Plotting all features in one plot\n",
    "fig, axes = plt.subplots(figsize=(15, 10))\n",
    "fig.suptitle('Scatter Plots for Different Features')\n",
    "\n",
    "for feature in features_to_plot:\n",
    "    axes.scatter(data.index, data[feature], alpha=0.5, label=feature)\n",
    "\n",
    "axes.set_xlabel('Data Points')\n",
    "axes.set_ylabel('Feature Values')\n",
    "axes.legend()\n",
    "plt.show()\n",
    "\n",
    "# print(len(features_to_plot))\n",
    "\n",
    "# fig = px.scatter(data, x=data.index, y=features_to_plot, labels={'x': 'Data Points'},\n",
    "#                  title='Interactive Scatter Plot for Ten Different Features')\n",
    "\n",
    "# fig.update_layout(showlegend=True)\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e62f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebc3ef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7cc027",
   "metadata": {},
   "source": [
    "##  Elbow - method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b24ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## These should be the versions to run kmeans.fit.... else it will give an error\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.show_versions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993518dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_person_days= df.groupby('State lgd code')['Total person days'].sum().reset_index()\n",
    "state_person_days1 = df.groupby('State')['Total person days'].sum().reset_index()\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "state_person_days[['Total person days']] = scaler.fit_transform(state_person_days[['Total person days']])\n",
    "\n",
    "# Define a range of K values to test\n",
    "k_values = range(1, 11)  # You can adjust the range as needed\n",
    "\n",
    "# Calculate the sum of squared distances (inertia) for different K values\n",
    "inertia = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(state_person_days[['Total person days']])\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the inertia values against K values\n",
    "plt.plot(k_values, inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6441d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_person_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29828a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_person_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "state_person_days['Cluster'] = kmeans.fit_predict(state_person_days[['Total person days']])\n",
    "state_person_days1['Cluster']=state_person_days['Cluster']\n",
    "\n",
    "# Create an interactive plot\n",
    "fig = px.scatter(state_person_days1, x='Total person days', color='Cluster', hover_name='State', title='State Clustering by Total Person-Days')\n",
    "fig.update_layout(xaxis_title='Total Person-Days (Scaled)')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Plot the clustered data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(state_person_days1['Total person days'], state_person_days1['Cluster'], c=state_person_days1['Cluster'], cmap='viridis')\n",
    "plt.title('State Clustering by Total Person-Days')\n",
    "plt.xlabel('Total Person-Days (Scaled)')\n",
    "plt.ylabel('Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_clustering = ['Job cards issued', 'Total person days', 'Labour expenditure that has been disbursed']  # You can select other columns as well\n",
    "\n",
    "# Create a subset of the data with the selected columns\n",
    "data_for_clustering = df[columns_for_clustering]\n",
    "\n",
    "# Standardize the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data_for_clustering)\n",
    "\n",
    "# Specify the number of clusters (K) you want to create\n",
    "num_clusters = 3  # You can choose the desired number of clusters\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "df['Cluster'] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Visualize the clustered data\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster in range(num_clusters):\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    plt.scatter(cluster_data[columns_for_clustering[0]], cluster_data[columns_for_clustering[1]], label=f'Cluster {cluster}')\n",
    "\n",
    "plt.xlabel(columns_for_clustering[0])\n",
    "plt.ylabel(columns_for_clustering[1])\n",
    "plt.title(f'K-Means Clustering ({num_clusters} Clusters)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2426e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the columns for clustering\n",
    "columns_for_clustering = ['Job cards issued', \n",
    "                          'Total person days',\n",
    "                          'Persons that worked under mahatma gandhi national rural employment guarantee act (mgnrega)']\n",
    "\n",
    "# Group the data by 'State' and calculate the sum of selected columns for each state\n",
    "state_data = df.groupby('State')[columns_for_clustering].sum().reset_index()\n",
    "\n",
    "# Standardize the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(state_data[columns_for_clustering])\n",
    "\n",
    "# Specify the number of clusters (K) you want to create\n",
    "num_clusters = 3  # You can choose the desired number of clusters\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "state_data['Cluster'] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Visualize the clustered data\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster in range(num_clusters):\n",
    "    cluster_data = state_data[state_data['Cluster'] == cluster]\n",
    "    plt.scatter(cluster_data[columns_for_clustering[0]], cluster_data[columns_for_clustering[1]], label=f'Cluster {cluster}')\n",
    "\n",
    "plt.xlabel(columns_for_clustering[0])\n",
    "plt.ylabel(columns_for_clustering[1])\n",
    "plt.title(f'K-Means Clustering of States ({num_clusters} Clusters)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16db27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features for clustering\n",
    "features = ['Labour expenditure that has been disbursed', 'Material expenditure that has been disbursed', 'Total person days']\n",
    "\n",
    "# Subset the data with selected features\n",
    "data = df[features]\n",
    "\n",
    "# Standardize the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Determine the optimal number of clusters (K) using the elbow method\n",
    "inertia = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(scaled_data)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow method to choose K\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, 11), inertia, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia (Within-Cluster Sum of Squares)')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Based on the elbow method, choose an optimal K value (e.g., K=3)\n",
    "\n",
    "# Apply K-Means clustering with the chosen K\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans.fit(scaled_data)\n",
    "\n",
    "# Add cluster labels to the original DataFrame\n",
    "df['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.figure(figsize=(10, 8))\n",
    "for cluster in df['Cluster'].unique():\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    plt.scatter(cluster_data[features[0]], cluster_data[features[1]], label=f'Cluster {cluster}')\n",
    "\n",
    "plt.xlabel(features[0])\n",
    "plt.ylabel(features[1])\n",
    "plt.title('Clustering: Expenditure Efficiency')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# You can further analyze and interpret the clusters, and access the cluster centroids using kmeans.cluster_centers_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc1be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features for clustering\n",
    "features = ['Labour expenditure that has been disbursed', 'Material expenditure that has been disbursed', 'Total person days']\n",
    "\n",
    "# Subset the data with selected features\n",
    "data = df[features]\n",
    "\n",
    "# Standardize the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# # Determine the optimal number of clusters (K) using the elbow method\n",
    "# inertia = []\n",
    "# for k in range(1, 11):\n",
    "#     kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "#     kmeans.fit(scaled_data)\n",
    "#     inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Apply K-Means clustering with the chosen K\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans.fit(scaled_data)\n",
    "\n",
    "# Add cluster labels to the original DataFrame\n",
    "df['Cluster'] = kmeans.labels_\n",
    "\n",
    "plt.scatter(df[features[0]], df[features[2]], c=df['Cluster'], cmap='viridis')\n",
    "plt.title('Non-Interactive Clustering: Expenditure Efficiency')\n",
    "plt.xlabel(features[0])\n",
    "plt.ylabel(features[2])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee2c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please run this cell to see interactive plot\n",
    "\n",
    "features = ['Labour expenditure that has been disbursed', 'Material expenditure that has been disbursed', 'Total person days']\n",
    "\n",
    "# Subset the data with selected features\n",
    "data = df[features]\n",
    "\n",
    "# Standardize the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "# Apply K-Means clustering with the chosen K\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans.fit(scaled_data)\n",
    "\n",
    "# Add cluster labels to the original DataFrame\n",
    "df['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Create an interactive scatter plot using Plotly\n",
    "fig = px.scatter_3d(df, x=features[0],y=features[1], z=features[2], color='Cluster', hover_name=df.index)\n",
    "\n",
    "# Customize the plot layout\n",
    "fig.update_layout(\n",
    "    title='Interactive Clustering: Expenditure Efficiency',\n",
    "   scene=dict(xaxis_title=features[0], yaxis_title=features[1],\n",
    "              zaxis_title=features[2]),\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195bf191",
   "metadata": {},
   "source": [
    "####  Kmeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Labour expenditure that has been disbursed', 'Material expenditure that has been disbursed', 'Total person days']\n",
    "\n",
    "#Subset the data with selected features\n",
    "data = df[features]\n",
    "\n",
    "# Standardize the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Apply K-Means clustering with the chosen K\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(scaled_data)\n",
    "\n",
    "# Calculate the Silhouette Score\n",
    "silhouette_avg = silhouette_score(scaled_data, kmeans.labels_)\n",
    "print(f'Silhouette Score: {silhouette_avg}')\n",
    "\n",
    "# Add cluster labels to the original DataFrame\n",
    "df['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Create an interactive scatter plot using Plotly\n",
    "fig = px.scatter_3d(df, x=features[0], y=features[1], z=features[2], color='Cluster', hover_name=df.index)\n",
    "\n",
    "# Customize the plot layout\n",
    "fig.update_layout(\n",
    "    title='Interactive Clustering: Expenditure Efficiency',\n",
    "    scene=dict(xaxis_title=features[0], yaxis_title=features[1], zaxis_title=features[2]),\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994a01ea",
   "metadata": {},
   "source": [
    "#### Clustering with change of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bdccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features for clustering\n",
    "features = ['Yearcode', 'Persons who demanded work', 'Labour expenditure both disbursed and pending']  # Adjust as needed\n",
    "\n",
    "# Subset the data with selected features\n",
    "data = df[features]\n",
    "\n",
    "# Standardize the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Choose the number of clusters (K) based on your objectives\n",
    "k = 3  # You can adjust this value\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "df['Cluster'] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Create a 3D scatter plot using Plotly\n",
    "fig = px.scatter_3d(df, x=features[0], y=features[1], z=features[2], color='Cluster',\n",
    "                    hover_name='Yearcode', title='3D Scatter Plot of Year-to-Year Changes')\n",
    "\n",
    "# Customize the plot layout\n",
    "fig.update_layout(scene=dict(xaxis_title=features[0], yaxis_title=features[1], zaxis_title=features[2]))\n",
    "\n",
    "# Show the interactive 3D plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd4b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Yearcode', 'Persons who demanded work', 'Labour expenditure both disbursed and pending']  # Adjust as needed\n",
    "\n",
    "data = df[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Choose the number of clusters (K) based on your objectives\n",
    "k = 3  # You can adjust this value\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "df['Cluster'] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Visualize the results\n",
    "# Example: Plot year-to-year changes within clusters\n",
    "for cluster in df['Cluster'].unique():\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    plt.figure()\n",
    "    for year in cluster_data['Yearcode'].unique():\n",
    "        year_data = cluster_data[cluster_data['Yearcode'] == year]\n",
    "        plt.plot(year_data['Yearcode'], year_data['Persons who demanded work'], label=f'Cluster {cluster}, Yearcode {year}')\n",
    "\n",
    "    plt.title(f'Year-to-Year Changes in Work Demand (Cluster {cluster})')\n",
    "    plt.xlabel('Yearcode')\n",
    "    plt.ylabel('Persons who demanded work')\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56065eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Yearcode', 'Persons who demanded work', 'Labour expenditure both disbursed and pending']  # Adjust as needed\n",
    "\n",
    "data = df[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Choose the number of clusters (K) based on your objectives\n",
    "k = 3  # You can adjust this value\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "df['Cluster'] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster in df['Cluster'].unique():\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    plt.scatter(cluster_data['Yearcode'], cluster_data['Persons who demanded work'], label=f'Cluster {cluster}')\n",
    "\n",
    "plt.title('Clustering of Year vs. Work Demand')\n",
    "plt.xlabel('Yearcode')\n",
    "plt.ylabel('Work Demand')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # Create an interactive scatter plot using Plotly\n",
    "# fig = px.scatter(df, x='Yearcode', y='Persons who demanded work', color='Cluster', hover_name=df.index)\n",
    "\n",
    "# # Customize the plot layout\n",
    "# fig.update_layout(\n",
    "#     title='Interactive Clustering of Year vs. Work Demand',\n",
    "#     xaxis_title='Yearcode',\n",
    "#     yaxis_title='Persons who demanded work'\n",
    "# )\n",
    "\n",
    "# # Show the interactive plot\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ab7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_column = 'Total person days'\n",
    "y_column = 'Labour expenditure that has been disbursed'\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df[x_column], df[y_column], alpha=0.5)\n",
    "plt.xlabel(x_column)\n",
    "plt.ylabel(y_column)\n",
    "plt.title(f'Scatter Plot: {x_column} vs. {y_column}')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e068b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df.columns\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_column = 'Total person days'\n",
    "y_column = 'Labour expenditure that has been disbursed'\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df[x_column], df[y_column], alpha=0.5)\n",
    "plt.xlabel(x_column)\n",
    "plt.ylabel(y_column)\n",
    "plt.title(f'Scatter Plot: {x_column} vs. {y_column}')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a30867",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db4322",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf050c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['State', 'District']\n",
    "df.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fc027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee65dc8",
   "metadata": {},
   "source": [
    "# 2d plot for nC2 [Manual Inspection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2cd596",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting for any 2 combinations of columns to see if we can extract something out of data\n",
    "\n",
    "feature_columns = df.columns\n",
    "\n",
    "# Generate scatter plots for all combinations of two features\n",
    "combinations = list(itertools.combinations(feature_columns, 2))\n",
    "\n",
    "for combo in combinations:\n",
    "    x_column, y_column = combo\n",
    "\n",
    "    # Create the scatter plot\n",
    "    plt.scatter(df[x_column], df[y_column], alpha=0.5)\n",
    "    plt.xlabel(x_column)\n",
    "    plt.ylabel(y_column)\n",
    "    plt.title(f'Scatter Plot: {x_column} vs {y_column}')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8956764a",
   "metadata": {},
   "source": [
    "# 3d plots nC3 [Manual Inspection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d5512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import itertools\n",
    "\n",
    "# Get all feature columns\n",
    "feature_columns = dff.columns\n",
    "\n",
    "# Generate 3D scatter plots for all combinations of three features\n",
    "combinations = list(itertools.combinations(feature_columns, 3))\n",
    "\n",
    "for combo in combinations:\n",
    "    x_column, y_column, z_column = combo\n",
    "\n",
    "    # Create the 3D scatter plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(dff[x_column], dff[y_column], dff[z_column], alpha=0.5)\n",
    "    ax.set_xlabel(x_column)\n",
    "    ax.set_ylabel(y_column)\n",
    "    ax.set_zlabel(z_column)\n",
    "    plt.title(f'3D Scatter Plot: {x_column} vs {y_column} vs {z_column}')\n",
    "\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d32507",
   "metadata": {},
   "source": [
    "<!-- Households that demanded work vs person with disability\n",
    "Households that demanded work vs Non scheduled tribes or scheduled caste households that worked\n",
    "Households that demanded work vs Total person days worked by non scheduled tribes or scheduled caste persons\n",
    "Households that demanded work vs Total person days\n",
    "person who demanded work vs Households that were alloted work\n",
    "person that worked under mnrega vs total person days\n",
    "person with disability vs Scheduled caste households that worked\n",
    "\n",
    "person with disability vs total person days -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d444290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_column = 'Households that demanded work'\n",
    "y_column = 'Persons with disability'\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df[x_column], df[y_column], alpha=0.5)\n",
    "plt.xlabel(x_column)\n",
    "plt.ylabel(y_column)\n",
    "plt.title(f'Scatter Plot: {x_column} vs {y_column}')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5c0e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Print or visualize the correlation matrix to see which columns are least corelated\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325dbbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aedfb52",
   "metadata": {},
   "source": [
    "#### Finding least correlated columns to do clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91987023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the least correlated columns\n",
    "least_correlated_columns = []\n",
    "\n",
    "# Set a threshold for considering correlations as low\n",
    "correlation_threshold = 0.2  \n",
    "\n",
    "# Iterate through the correlation matrix to find least correlated columns\n",
    "for col1 in correlation_matrix.columns:\n",
    "    for col2 in correlation_matrix.columns:\n",
    "        if col1 != col2 and abs(correlation_matrix[col1][col2]) < correlation_threshold:\n",
    "            least_correlated_columns.append((col1, col2, correlation_matrix[col1][col2]))\n",
    "\n",
    "# Sort the least correlated column pairs by correlation coefficient\n",
    "least_correlated_columns.sort(key=lambda x: x[2])\n",
    "\n",
    "# Print the least correlated column pairs\n",
    "for col1, col2, correlation in least_correlated_columns:\n",
    "    print(f\"Columns: {col1} and {col2}, Correlation: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd5df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting each corelated column to inspect for clusters\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Find the least correlated columns\n",
    "least_corr_columns = []\n",
    "\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) < 0.1:  # Adjust the correlation threshold as needed\n",
    "            least_corr_columns.append((corr_matrix.columns[i], corr_matrix.columns[j]))\n",
    "\n",
    "# Create scatter plots for the least correlated pairs\n",
    "for pair in least_corr_columns:\n",
    "    x_col, y_col = pair\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(df[x_col], df[y_col], alpha=0.5)\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    plt.title(f'Scatter Plot: {x_col} vs {y_col}')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d72764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pairs = [\n",
    "    ('Households that demanded work', 'Persons with disability'),\n",
    "    ('Households that demanded work', 'Non scheduled tribes or scheduled caste houeholds that worked'),\n",
    "    ('Households that demanded work', 'Total person days worked by non scheduled tribes or scheduled caste persons.'),\n",
    "    ('Households that demanded work', 'Total person days'),\n",
    "    ('Persons who demanded work', 'Households that were allotted work'),\n",
    "    ('Persons that worked under mahatma gandhi national rural employment guarantee act (mgnrega)', 'Total person days'),\n",
    "    ('Persons with disability', 'Scheduled caste houeholds that worked'),\n",
    "    ('Persons with disability', 'Total person days')\n",
    "]\n",
    "\n",
    "# Create scatter plots for each pair\n",
    "for x_col, y_col in pairs:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(df[x_col], df[y_col], alpha=0.5)\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    plt.title(f'Scatter Plot: {x_col} vs {y_col}')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc269d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Households that demanded work','Non scheduled tribes or scheduled caste houeholds that worked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d91498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = df[['Households that demanded work', 'Non scheduled tribes or scheduled caste houeholds that worked']]\n",
    "\n",
    "# Standardize the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Determine the optimal number of clusters using the Elbow method\n",
    "wcss = []  # Within-Cluster-Sum-of-Squares\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=0)\n",
    "    kmeans.fit(scaled_data)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow method graph\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, 11), wcss, marker='o', linestyle='--')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Within-Cluster-Sum-of-Squares (WCSS)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0342c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3  # You can adjust this value\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "df['Cluster'] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster in df['Cluster'].unique():\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    plt.scatter(\n",
    "        cluster_data['Households that demanded work'],\n",
    "        cluster_data['Non scheduled tribes or scheduled caste houeholds that worked'],\n",
    "        label=f'Cluster {cluster}'\n",
    "    )\n",
    "\n",
    "plt.xlabel('Households that demanded work')\n",
    "plt.ylabel('Non scheduled tribes or scheduled caste houeholds that worked')\n",
    "plt.title('K-Means Clustering')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c2886",
   "metadata": {},
   "source": [
    "## Kmeans with log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_log =data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c0725",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data_for_log.columns:\n",
    "#     if column.startswith('Values'):  # You can specify which columns to transform\n",
    "    data_for_log[f'{column}_Log'] = np.log(data_for_log[column]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa9362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Households that demanded work', 'Non scheduled tribes or scheduled caste houeholds that worked']\n",
    "data_for_log = data_for_log.drop(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea8013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d741d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the optimal number of clusters using the Elbow method\n",
    "wcss = []  # Within-Cluster-Sum-of-Squares\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=0)\n",
    "    kmeans.fit(data_for_log)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow method graph\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, 11), wcss, marker='o', linestyle='--')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Within-Cluster-Sum-of-Squares (WCSS)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2  # You can adjust this value\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "data_for_log['Cluster'] = kmeans.fit_predict(data_for_log)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster in data_for_log['Cluster'].unique():\n",
    "    cluster_data = data_for_log[data_for_log['Cluster'] == cluster]\n",
    "    plt.scatter(\n",
    "        cluster_data['Households that demanded work_Log'],\n",
    "        cluster_data['Non scheduled tribes or scheduled caste houeholds that worked_Log'],\n",
    "        label=f'Cluster {cluster}'\n",
    "    )\n",
    "\n",
    "plt.xlabel('Households that demanded work')\n",
    "plt.ylabel('Non scheduled tribes or scheduled caste houeholds that worked')\n",
    "plt.title('K-Means Clustering')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fee841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9794cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ec4e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c7ec95f",
   "metadata": {},
   "source": [
    "#### Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a53b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features for clustering\n",
    "features = ['Households that demanded work', 'Non scheduled tribes or scheduled caste houeholds that worked']  # Adjust as needed\n",
    "\n",
    "data = df[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Choose the number of clusters (K) based on your objectives\n",
    "k = 3  # You can adjust this value\n",
    "\n",
    "# Perform Spectral Clustering\n",
    "spectral = SpectralClustering(n_clusters=k, affinity='nearest_neighbors')\n",
    "df['Cluster'] = spectral.fit_predict(scaled_data)\n",
    "\n",
    "# Visualize the results\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df[features[0]], df[features[1]], c=df['Cluster'], cmap='viridis')\n",
    "plt.title('Spectral Clustering')\n",
    "plt.xlabel(features[0])\n",
    "plt.ylabel(features[1])\n",
    "plt.show()\n",
    "silhouette_avg = silhouette_score(scaled_data, df['Cluster'])\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e003bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features for clustering\n",
    "features = ['Households that demanded work', 'Non scheduled tribes or scheduled caste houeholds that worked']  # Adjust as needed\n",
    "\n",
    "data = df[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Choose the number of clusters (K) based on your objectives\n",
    "k = 3  # You can adjust this value\n",
    "\n",
    "# Perform Spectral Clustering\n",
    "spectral = SpectralClustering(n_clusters=k, affinity='rbf')\n",
    "df['Cluster'] = spectral.fit_predict(scaled_data)\n",
    "\n",
    "# Visualize the results\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df[features[0]], df[features[1]], c=df['Cluster'], cmap='viridis')\n",
    "plt.title('Spectral Clustering')\n",
    "plt.xlabel(features[0])\n",
    "plt.ylabel(features[1])\n",
    "plt.show()\n",
    "\n",
    "silhouette_avg = silhouette_score(scaled_data, df['Cluster'])\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf1012",
   "metadata": {},
   "source": [
    "#### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7977a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features for clustering\n",
    "features = ['Households that demanded work', 'Non scheduled tribes or scheduled caste houeholds that worked']  # Adjust as needed\n",
    "\n",
    "data = df[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Choose the number of clusters (n_clusters) based on your objectives\n",
    "n_clusters =3  # You can adjust this value\n",
    "\n",
    "# Perform Agglomerative Clustering\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward',  affinity='euclidean' )\n",
    "df['Cluster'] = agg_clustering.fit_predict(scaled_data)\n",
    "\n",
    "# Visualize the results\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df[features[0]], df[features[1]], c=df['Cluster'], cmap='viridis')\n",
    "plt.title('Agglomerative Clustering')\n",
    "plt.xlabel(features[0])\n",
    "plt.ylabel(features[1])\n",
    "plt.show()\n",
    "\n",
    "silhouette_avg = silhouette_score(scaled_data, df['Cluster'])\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fde737",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_matrix = linkage(scaled_data, method='ward')  # Adjust the linkage method as needed\n",
    "\n",
    "# Plot the dendrogram\n",
    "plt.figure(figsize=(12, 8))\n",
    "dendrogram(linkage_matrix, labels=df.index, orientation='top', leaf_rotation=0, leaf_font_size=10)\n",
    "plt.title('Dendrogram for Agglomerative Clustering')\n",
    "plt.xlabel('Data Points')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65891f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8546e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Households that demanded work', 'Non scheduled tribes or scheduled caste houeholds that worked']  # Adjust as needed\n",
    "\n",
    "data = df[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Perform DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=1, min_samples=7)  # Adjust parameters (eps and min_samples) as needed\n",
    "df['Cluster'] = dbscan.fit_predict(scaled_data)\n",
    "\n",
    "# Visualize the results\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df[features[0]], df[features[1]], c=df['Cluster'], cmap='viridis')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.xlabel(features[0])\n",
    "plt.ylabel(features[1])\n",
    "plt.show()\n",
    "\n",
    "silhouette_avg = silhouette_score(scaled_data, df['Cluster'])\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2afcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Define the number of components (clusters) for GMM\n",
    "n_components =  3 # Adjust the number of components as needed\n",
    "\n",
    "# Create a GMM model\n",
    "gmm = GaussianMixture(n_components=n_components)\n",
    "\n",
    "# Fit the model to the scaled data\n",
    "gmm.fit(scaled_data)\n",
    "\n",
    "# Predict the cluster labels\n",
    "df['GMM_Cluster'] = gmm.predict(scaled_data)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df[features[0]], df[features[1]], c=df['GMM_Cluster'], cmap='viridis')\n",
    "plt.title('GMM Clustering')\n",
    "plt.xlabel(features[0])\n",
    "plt.ylabel(features[1])\n",
    "plt.show()\n",
    "\n",
    "# Compute the Silhouette Score for GMM\n",
    "gmm_silhouette_avg = silhouette_score(scaled_data, df['GMM_Cluster'])\n",
    "print(f\"GMM Silhouette Score: {gmm_silhouette_avg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9895147d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060834a4",
   "metadata": {},
   "source": [
    "## Checking if state can do something to form clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9920672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace 'selected_columns' with a list of columns you want to visualize\n",
    "selected_columns = ['Households that applied for a job card', 'Job cards issued',\n",
    "       'Job cards issued for scheduled caste',\n",
    "       'Job cards issued for scheduled tribes',\n",
    "       'Job cards issued for non scheduled tribes or scheduled caste',\n",
    "       'Households that demanded work', 'Persons who demanded work',\n",
    "       'Households that were allotted work', 'Persons that were allotted work',\n",
    "       'Muster rolls filled',\n",
    "       'Households that worked under mahatma gandhi national rural employment guarantee act (mgnrega)',\n",
    "       'Persons that worked under mahatma gandhi national rural employment guarantee act (mgnrega)',\n",
    "       'Households that reached a 100 day limit', 'Persons with disability',\n",
    "       'Non scheduled tribes or scheduled caste houeholds that worked',\n",
    "       'Total person days worked by non scheduled tribes or scheduled caste persons.',\n",
    "       'Scheduled caste houeholds that worked',\n",
    "       'Total person days worked scheduled caste persons',\n",
    "       'Scheduled tribe houeholds that worked',\n",
    "       'Total person days worked scheduled tribe persons',\n",
    "       'Households that worked on land reform or indira awas yojana',\n",
    "       'Total person days worked by women', 'Total person days',\n",
    "       'Scheduled caste households that reached a 100 day limit',\n",
    "       'Scheduled tribe households that reached a 100 day limit',\n",
    "       'Labour expenditure that has been disbursed',\n",
    "       'Material expenditure that has been disbursed',\n",
    "       'Labour expenditure both disbursed and pending',\n",
    "       'Material expenditure both disbursed and pending', 'Amount sanctioned',\n",
    "       'Works under mahatma gandhi national rural employment guarantee act (mgnrega)',\n",
    "       'Total bank accounts', 'Individual bank accounts',\n",
    "       'Joint bank accounts', 'Amount disbursed to bank accounts',\n",
    "       'Post office accounts', 'Individual post office accounts',\n",
    "       'Joint post office accounts',\n",
    "       'Amount disbursed to post office accounts']\n",
    "\n",
    "# Loop through selected columns and create scatter plots\n",
    "for column in selected_columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df['State lgd code'], df[column], alpha=0.5)\n",
    "    plt.xlabel('State lgd code')\n",
    "    plt.ylabel(column)\n",
    "    plt.title(f'Scatter Plot: State vs {column}')\n",
    "    plt.xticks(rotation=90)  # Rotate x-axis labels for better visibility\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0b2f8c",
   "metadata": {},
   "source": [
    "## K Means on state vs Amt disbursed to PO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913dc0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "# Select the columns for clustering\n",
    "columns = ['Amount disbursed to post office accounts']\n",
    "\n",
    "# Create a DataFrame with the selected columns\n",
    "data = df[columns]\n",
    "\n",
    "# Initialize the K-Means model with the desired number of clusters (K)\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "\n",
    "# Fit the K-Means model to the data\n",
    "kmeans.fit(data)\n",
    "\n",
    "# Add cluster labels to the original DataFrame\n",
    "df['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Display the cluster assignments for each state\n",
    "clustered_data = df[['State lgd code', 'Cluster']]\n",
    "print(clustered_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff033cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "for cluster in df['Cluster'].unique():\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    plt.scatter(cluster_data['State lgd code'], cluster_data['Amount disbursed to post office accounts'], label=f'Cluster {cluster}', alpha=0.5)\n",
    "\n",
    "plt.title('K-Means Clustering: State vs Amount Disbursed to Post Office Accounts')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Amount Disbursed to Post Office Accounts')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)  # Rotate state names for better visibility\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652817a6",
   "metadata": {},
   "source": [
    "## Using Kmeans ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f005fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame 'df' with the relevant data\n",
    "data = df[['State lgd code', 'Amount disbursed to post office accounts']]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Apply K-Means clustering with K-Means++\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++', random_state=0)\n",
    "df['Cluster'] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "for cluster in df['Cluster'].unique():\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    plt.scatter(cluster_data['State lgd code'], cluster_data['Amount disbursed to post office accounts'], label=f'Cluster {cluster}', alpha=0.5)\n",
    "\n",
    "plt.title('K-Means Clustering (K-Means++) - State vs Amount Disbursed to Post Office Accounts')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Amount Disbursed to Post Office Accounts')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39600324",
   "metadata": {},
   "source": [
    "## Using Spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813af618",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the features for clustering\n",
    "features =['State lgd code', 'Amount disbursed to post office accounts']\n",
    "data = df[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Choose the number of clusters (K) based on your objectives\n",
    "k = 3  # You can adjust this value\n",
    "\n",
    "# Perform Spectral Clustering\n",
    "spectral = SpectralClustering(n_clusters=k, affinity='nearest_neighbors')\n",
    "df['Cluster'] = spectral.fit_predict(scaled_data)\n",
    "\n",
    "# Visualize the results\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df[features[0]], df[features[1]], c=df['Cluster'], cmap='viridis')\n",
    "plt.title('Spectral Clustering')\n",
    "plt.xlabel(features[0])\n",
    "plt.ylabel(features[1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5c3e4e",
   "metadata": {},
   "source": [
    "## Spectral with rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features for clustering\n",
    "features =['State lgd code', 'Amount disbursed to post office accounts']\n",
    "data = df[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Choose the number of clusters (K) based on your objectives\n",
    "k = 3  # You can adjust this value\n",
    "\n",
    "# Perform Spectral Clustering\n",
    "spectral = SpectralClustering(n_clusters=k, affinity='rbf')\n",
    "df['Cluster'] = spectral.fit_predict(scaled_data)\n",
    "\n",
    "# Visualize the results\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df[features[0]], df[features[1]], c=df['Cluster'], cmap='viridis')\n",
    "plt.title('Spectral Clustering')\n",
    "plt.xlabel(features[0])\n",
    "plt.ylabel(features[1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f78e022",
   "metadata": {},
   "source": [
    "## Agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73708c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features for clustering\n",
    "\n",
    "features =['State lgd code', 'Amount disbursed to post office accounts']\n",
    "data = df[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Choose the number of clusters (n_clusters) based on your objectives\n",
    "n_clusters =2  # You can adjust this value\n",
    "\n",
    "# Perform Agglomerative Clustering\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "df['Cluster'] = agg_clustering.fit_predict(scaled_data)\n",
    "\n",
    "# Visualize the results\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df[features[0]], df[features[1]], c=df['Cluster'], cmap='viridis')\n",
    "plt.title('Agglomerative Clustering')\n",
    "plt.xlabel(features[0])\n",
    "plt.ylabel(features[1])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d53bc",
   "metadata": {},
   "source": [
    "## DBScan Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40867886",
   "metadata": {},
   "outputs": [],
   "source": [
    "features =['State lgd code', 'Amount disbursed to post office accounts']\n",
    "\n",
    "data = df[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Perform DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=0.7, min_samples=5)  # Adjust parameters (eps and min_samples) as needed\n",
    "df['Cluster'] = dbscan.fit_predict(scaled_data)\n",
    "\n",
    "# Visualize the results\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df[features[0]], df[features[1]], c=df['Cluster'], cmap='viridis')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.xlabel(features[0])\n",
    "plt.ylabel(features[1])\n",
    "plt.show()\n",
    "\n",
    "silhouette_avg = silhouette_score(scaled_data, df['Cluster'])\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cd7d38",
   "metadata": {},
   "source": [
    "### Working on mean_tsne data which has 2 dimensions based on mean values corresponding to each state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4023b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tsne = pd.read_csv(\"mean_tsne.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e5175",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e662fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Component_1', 'Component_2']\n",
    "data_for_clustering = mean_tsne[features]\n",
    "\n",
    "# Determine the optimal number of clusters (K) using the elbow method\n",
    "inertia = []\n",
    "k_values = range(1, 11)  # Range of K values to test\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(data_for_clustering)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the inertia values against K values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_values, inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a2488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4  # You can adjust the number of clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "mean_tsne['Cluster'] = kmeans.fit_predict(data_for_clustering)\n",
    "\n",
    "# Plotting the clustered mean t-SNE values\n",
    "fig = px.scatter(\n",
    "    mean_tsne,\n",
    "    x='Component_1',\n",
    "    y='Component_2',\n",
    "    color='Cluster',\n",
    "    title=f'K-Means Clustering of Mean t-SNE Values (K={n_clusters})',\n",
    "    labels={'Component_1': 'Mean Component 1', 'Component_2': 'Mean Component 2'}\n",
    ")\n",
    "\n",
    "silhouette_avg = silhouette_score(data_for_clustering, mean_tsne['Cluster'])\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887338e3",
   "metadata": {},
   "source": [
    "### Working on mean_tsne_district data which has 2 dimensions based on mean values corresponding to each state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tsne_district = pd.read_csv(\"mean_tsne_district.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d3f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tsne_district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544bd08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234cac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'district' column exists in both DataFrames\n",
    "result_df = pd.merge(mean_tsne_district, df[['District', 'State']], on='District', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f4cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Component_1', 'Component_2']\n",
    "data_for_clustering = result_df[features]\n",
    "\n",
    "# Determine the optimal number of clusters (K) using the elbow method\n",
    "inertia = []\n",
    "k_values = range(1, 11)  # Range of K values to test\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(data_for_clustering)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the inertia values against K values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_values, inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b18a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b2af69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b19a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fdeede",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    result_df,\n",
    "    x='Component_1',\n",
    "    y='Component_2',\n",
    "    hover_name = result_df['State'],\n",
    "    color='District',\n",
    "    title='Mean t-SNE Values by State (2D)',\n",
    "    labels={'Component_1': 'Mean Component 1', 'Component_2': 'Mean Component 2'}\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eefb8c",
   "metadata": {},
   "source": [
    "### Kmeans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4968ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4  # You can adjust the number of clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "result_df['Cluster'] = kmeans.fit_predict(data_for_clustering)\n",
    "\n",
    "# Plotting the clustered mean t-SNE values\n",
    "fig = px.scatter(\n",
    "    result_df,\n",
    "    x='Component_1',\n",
    "    y='Component_2',\n",
    "    color='Cluster',\n",
    "    title=f'K-Means Clustering of Mean t-SNE Values (K={n_clusters})',\n",
    "    labels={'Component_1': 'Mean Component 1', 'Component_2': 'Mean Component 2'}\n",
    ")\n",
    "\n",
    "silhouette_avg = silhouette_score(data_for_clustering, result_df['Cluster'])\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db65b2af",
   "metadata": {},
   "source": [
    "### Kmeans ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5576958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4  # You can adjust the number of clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters,init='k-means++', random_state=42)\n",
    "result_df['Cluster'] = kmeans.fit_predict(data_for_clustering)\n",
    "\n",
    "# Plotting the clustered mean t-SNE values\n",
    "fig = px.scatter(\n",
    "    result_df,\n",
    "    x='Component_1',\n",
    "    y='Component_2',\n",
    "    color='Cluster',\n",
    "    title=f'K-Means Clustering of Mean t-SNE Values (K={n_clusters})',\n",
    "    labels={'Component_1': 'Mean Component 1', 'Component_2': 'Mean Component 2'}\n",
    ")\n",
    "\n",
    "\n",
    "silhouette_avg = silhouette_score(data_for_clustering, result_df['Cluster'])\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393cbdd0",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a01bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "n_components = 4 # Number of clusters\n",
    "gmm = GaussianMixture(n_components=n_components, random_state=42)\n",
    "result_df['Cluster'] = gmm.fit_predict(data_for_clustering)\n",
    "\n",
    "# Plotting the clustered mean t-SNE values with GMM\n",
    "fig = px.scatter(\n",
    "    result_df,\n",
    "    x='Component_1',\n",
    "    y='Component_2',\n",
    "    color='Cluster',\n",
    "    title=f'Gaussian Mixture Model Clustering of Mean t-SNE Values (n_components={n_components})',\n",
    "    labels={'Component_1': 'Mean Component 1', 'Component_2': 'Mean Component 2'}\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "\n",
    "silhouette_avg = silhouette_score(data_for_clustering, result_df['Cluster'])\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f06c2",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df987cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 2   #ust epsilon as needed\n",
    "min_samples = 10  #djust min_samples as needed\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples,algorithm= 'kd_tree')\n",
    "\n",
    "# Fit DBSCAN to your data\n",
    "result_df['Cluster'] = dbscan.fit_predict(data_for_clustering)\n",
    "\n",
    "# Plotting the clustered data points (assuming 2D data)\n",
    "fig = px.scatter(\n",
    "    result_df,\n",
    "    x='Component_1',\n",
    "    y='Component_2',\n",
    "    color='Cluster',\n",
    "    title='DBSCAN Clustering',\n",
    "    labels={'Component_1': 'Component 1', 'Component_2': 'Component 2'}\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "\n",
    "silhouette_avg = silhouette_score(data_for_clustering, result_df['Cluster'])\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd62927",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bff29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Assuming 'data_for_clustering' contains your data for clustering\n",
    "\n",
    "# Set up Agglomerative Clustering\n",
    "n_clusters = 4  # Adjust the number of clusters as needed\n",
    "agglomerative = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "\n",
    "# Fit Agglomerative Clustering to your data\n",
    "result_df['Cluster'] = agglomerative.fit_predict(data_for_clustering)\n",
    "\n",
    "# Plotting the clustered data points (assuming 2D data)\n",
    "fig = px.scatter(\n",
    "    result_df,\n",
    "    x='Component_1',\n",
    "    y='Component_2',\n",
    "    color='Cluster',\n",
    "    title='Agglomerative Clustering',\n",
    "    labels={'Component_1': 'Component 1', 'Component_2': 'Component 2'}\n",
    ")\n",
    "\n",
    "silhouette_avg = silhouette_score(data_for_clustering, result_df['Cluster'])\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f5ff82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffbdba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
